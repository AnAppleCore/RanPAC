{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing: ../logs/adapter/cifar224/0/10/768_1/1993_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/768_1/1995_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/768_1/1994_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/default/1993_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/default/1995_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/default/1994_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/2000_1/1993_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/2000_1/1995_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/2000_1/1994_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/mean_2000_5/1993_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/mean_2000_5/1995_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/mean_2000_5/1994_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/mean_10000_5/1993_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/mean_10000_5/1995_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Processing: ../logs/adapter/cifar224/0/10/mean_10000_5/1994_pretrained_vit_b16_224_in21k_adapter.log\n",
      "Saved raw results to ranpac_results_raw.csv\n",
      "\n",
      "Found 5 complete experiments\n",
      "Found 0 incomplete experiments\n",
      "Saved statistics to ranpac_results_stats.csv\n",
      "\n",
      "Summary of results:\n",
      "model_name                         convnet_type     exp_name  dataset  num_seeds          seeds  final_accuracy_mean  final_accuracy_std  average_accuracy_mean  average_accuracy_std  forgetting_mean  forgetting_std\n",
      "   adapter pretrained_vit_b16_224_in21k_adapter       2000_1 cifar224          3 1993,1994,1995            91.070000            0.371618              94.539667              0.294546         3.700000        0.302051\n",
      "   adapter pretrained_vit_b16_224_in21k_adapter        768_1 cifar224          3 1993,1994,1995            90.216667            0.370720              93.899333              0.290655         4.051852        0.382702\n",
      "   adapter pretrained_vit_b16_224_in21k_adapter      default cifar224          3 1993,1994,1995            92.093333            0.296704              95.020667              0.205456         3.162963        0.191270\n",
      "   adapter pretrained_vit_b16_224_in21k_adapter mean_10000_5 cifar224          3 1993,1994,1995            92.240000            0.111355              95.132333              0.205332         3.162963        0.111849\n",
      "   adapter pretrained_vit_b16_224_in21k_adapter  mean_2000_5 cifar224          3 1993,1994,1995            91.333333            0.248462              94.708333              0.189088         3.532593        0.366905\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def parse_ranpac_log(log_file_path):\n",
    "    \"\"\"Parse a RanPAC log file to extract metrics.\"\"\"\n",
    "    with open(log_file_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    result = {\n",
    "        \"model_name\": \"\",\n",
    "        \"convnet_type\": \"\",\n",
    "        \"exp_name\": \"\",\n",
    "        \"dataset\": \"\",\n",
    "        \"seed\": \"\",\n",
    "        \"final_accuracy\": 0.0,\n",
    "        \"average_accuracy\": 0.0,\n",
    "        \"forgetting\": 0.0,\n",
    "    }\n",
    "    \n",
    "    # Parse header information\n",
    "    for line in lines:\n",
    "        if \"model_name:\" in line:\n",
    "            result[\"model_name\"] = line.split(\"model_name:\")[1].strip()\n",
    "        elif \"convnet_type:\" in line:\n",
    "            result[\"convnet_type\"] = line.split(\"convnet_type:\")[1].strip()\n",
    "        elif \"exp_name:\" in line:\n",
    "            result[\"exp_name\"] = line.split(\"exp_name:\")[1].strip()\n",
    "        elif \"dataset:\" in line:\n",
    "            result[\"dataset\"] = line.split(\"dataset:\")[1].strip()\n",
    "        elif \"seed:\" in line:\n",
    "            result[\"seed\"] = line.split(\"seed:\")[1].strip()\n",
    "    \n",
    "    # Extract filename seed if not found in log\n",
    "    if not result[\"seed\"]:\n",
    "        filename = os.path.basename(log_file_path)\n",
    "        seed_match = re.search(r'(\\d{4})_', filename)\n",
    "        if seed_match:\n",
    "            result[\"seed\"] = seed_match.group(1)\n",
    "    \n",
    "    # Extract final Top1 curve for final_accuracy and average_accuracy\n",
    "    top1_curves = []\n",
    "    for line in lines:\n",
    "        if \"Top1 curve:\" in line:\n",
    "            # Extract the list from the line\n",
    "            curve_str = line.split(\"Top1 curve:\")[1].strip()\n",
    "            try:\n",
    "                curve_values = ast.literal_eval(curve_str)\n",
    "                top1_curves.append(curve_values)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    if top1_curves:\n",
    "        final_curve = top1_curves[-1]  # Last Top1 curve\n",
    "        result[\"final_accuracy\"] = final_curve[-1]  # Last value in the curve\n",
    "        result[\"average_accuracy\"] = np.mean(final_curve)  # Mean of all values\n",
    "    \n",
    "    # Extract Group Accuracies for forgetting calculation\n",
    "    group_accuracies_history = defaultdict(list)\n",
    "    \n",
    "    for line in lines:\n",
    "        if \"Group Accuracies after this task:\" in line:\n",
    "            # Extract the dictionary from the line\n",
    "            acc_str = line.split(\"Group Accuracies after this task:\")[1].strip()\n",
    "            try:\n",
    "                # Parse the dictionary-like string\n",
    "                acc_dict = ast.literal_eval(acc_str)\n",
    "                for group, accuracy in acc_dict.items():\n",
    "                    group_accuracies_history[group].append(accuracy)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    # Calculate forgetting: last - max for each group, then average\n",
    "    forgetting_values = []\n",
    "    for group, accuracies in group_accuracies_history.items():\n",
    "        if len(accuracies) > 1:  # Need at least 2 values to calculate forgetting\n",
    "            max_acc = max(accuracies)\n",
    "            last_acc = accuracies[-1]\n",
    "            forgetting = max_acc - last_acc  # Forgetting = max - last\n",
    "            forgetting_values.append(forgetting)\n",
    "    \n",
    "    if forgetting_values:\n",
    "        result[\"forgetting\"] = np.mean(forgetting_values)\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "def parse_logs_folder(logs_folder):\n",
    "    \"\"\"Parse all log files in the logs folder.\"\"\"\n",
    "    all_results = []\n",
    "    \n",
    "    # Find all .log files recursively\n",
    "    for root, dirs, files in os.walk(logs_folder):\n",
    "        for file in files:\n",
    "            if file.endswith('.log'):\n",
    "                log_path = os.path.join(root, file)\n",
    "                print(f\"Processing: {log_path}\")\n",
    "                try:\n",
    "                    result = parse_ranpac_log(log_path)\n",
    "                    # Add path information for debugging\n",
    "                    result[\"log_path\"] = log_path\n",
    "                    \n",
    "                    # Extract exp_name from path if not found in log\n",
    "                    if not result[\"exp_name\"]:\n",
    "                        path_parts = log_path.split(os.sep)\n",
    "                        if len(path_parts) >= 2:\n",
    "                            result[\"exp_name\"] = path_parts[-2]  # Parent directory name\n",
    "                    \n",
    "                    all_results.append(result)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error processing {log_path}: {e}\")\n",
    "                    continue\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "def generate_csv_results(logs_folder, output_prefix=\"ranpac_results\"):\n",
    "    \"\"\"Generate CSV files with results and statistics.\"\"\"\n",
    "    all_results = parse_logs_folder(logs_folder)\n",
    "    \n",
    "    if not all_results:\n",
    "        print(\"No valid results found!\")\n",
    "        return\n",
    "    \n",
    "    # Create DataFrame\n",
    "    df = pd.DataFrame(all_results)\n",
    "    \n",
    "    # Rearrange columns\n",
    "    columns = [\"model_name\", \"convnet_type\", \"exp_name\", \"dataset\", \"seed\", \n",
    "               \"final_accuracy\", \"average_accuracy\", \"forgetting\", \"log_path\"]\n",
    "    df = df[columns]\n",
    "    \n",
    "    # Sort by relevant columns\n",
    "    df = df.sort_values(by=[\"model_name\", \"dataset\", \"convnet_type\", \"exp_name\", \"seed\"])\n",
    "    \n",
    "    # Save raw results\n",
    "    df.to_csv(f\"{output_prefix}_raw.csv\", index=False)\n",
    "    print(f\"Saved raw results to {output_prefix}_raw.csv\")\n",
    "    \n",
    "    # Group by experiment settings and calculate mean/std\n",
    "    groupby_cols = [\"model_name\", \"convnet_type\", \"exp_name\", \"dataset\"]\n",
    "    \n",
    "    # Check which experiments have complete seeds\n",
    "    grouped = df.groupby(groupby_cols)\n",
    "    complete_experiments = []\n",
    "    incomplete_experiments = []\n",
    "    \n",
    "    for name, group in grouped:\n",
    "        seeds = sorted(group[\"seed\"].astype(str).tolist())\n",
    "        if len(seeds) >= 3:  # Assuming we want at least 3 seeds\n",
    "            complete_experiments.append((name, group))\n",
    "        else:\n",
    "            incomplete_experiments.append((name, group, seeds))\n",
    "    \n",
    "    print(f\"\\nFound {len(complete_experiments)} complete experiments\")\n",
    "    print(f\"Found {len(incomplete_experiments)} incomplete experiments\")\n",
    "    \n",
    "    if incomplete_experiments:\n",
    "        print(\"\\nIncomplete experiments:\")\n",
    "        for name, group, seeds in incomplete_experiments:\n",
    "            print(f\"  {name}: seeds {seeds}\")\n",
    "    \n",
    "    # Calculate mean and std for complete experiments\n",
    "    if complete_experiments:\n",
    "        stats_data = []\n",
    "        \n",
    "        for name, group in complete_experiments:\n",
    "            stats = {\n",
    "                \"model_name\": name[0],\n",
    "                \"convnet_type\": name[1], \n",
    "                \"exp_name\": name[2],\n",
    "                \"dataset\": name[3],\n",
    "                \"num_seeds\": len(group),\n",
    "                \"seeds\": \",\".join(sorted(group[\"seed\"].astype(str))),\n",
    "                \"final_accuracy_mean\": group[\"final_accuracy\"].mean(),\n",
    "                \"final_accuracy_std\": group[\"final_accuracy\"].std(),\n",
    "                \"average_accuracy_mean\": group[\"average_accuracy\"].mean(),\n",
    "                \"average_accuracy_std\": group[\"average_accuracy\"].std(),\n",
    "                \"forgetting_mean\": group[\"forgetting\"].mean(),\n",
    "                \"forgetting_std\": group[\"forgetting\"].std(),\n",
    "            }\n",
    "            stats_data.append(stats)\n",
    "        \n",
    "        stats_df = pd.DataFrame(stats_data)\n",
    "        stats_df = stats_df.sort_values(by=[\"model_name\", \"dataset\", \"convnet_type\", \"exp_name\"])\n",
    "        stats_df.to_csv(f\"{output_prefix}_stats.csv\", index=False)\n",
    "        print(f\"Saved statistics to {output_prefix}_stats.csv\")\n",
    "        \n",
    "        # Display summary\n",
    "        print(\"\\nSummary of results:\")\n",
    "        print(stats_df.to_string(index=False))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "# Main execution\n",
    "logs_folder = \"../logs\"\n",
    "df = generate_csv_results(logs_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DGIL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
